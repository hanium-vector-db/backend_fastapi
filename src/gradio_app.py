import gradio as gr
import requests
import json
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì„œë²„ ì£¼ì†Œ
API_URL = "http://127.0.0.1:8001/api/v1"

def handle_api_error(response):
    """
    API ì‘ë‹µ ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•˜ê³  ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì„±ê³µ ì‹œ Noneì„, ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ë¬¸ìì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if response.status_code >= 400:
        try:
            detail = response.json().get("detail", "ì•Œ ìˆ˜ ì—†ëŠ” ì„œë²„ ì˜¤ë¥˜")
            return f"**ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ (HTTP {response.status_code})**\n\n**ì˜¤ë¥˜ ë‚´ìš©:**\n{detail}\n\n**ì„œë²„ ì‘ë‹µ ì›ë¬¸:**\n```\n{response.text}\n```"
        except json.JSONDecodeError:
            return f"**ì„œë²„ì—ì„œ ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ (HTTP {response.status_code})**\n\n**ì„œë²„ ì‘ë‹µ ì›ë¬¸:**\n```\n{response.text}\n```"
    return None

def make_api_call(endpoint, payload, method="post"):
    """ì¤‘ë³µë˜ëŠ” API í˜¸ì¶œ ë¡œì§ì„ ì²˜ë¦¬í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    try:
        if method.lower() == "post":
            response = requests.post(f"{API_URL}/{endpoint}", json=payload, timeout=300) # íƒ€ì„ì•„ì›ƒ ì¦ê°€
        else:
            response = requests.get(f"{API_URL}/{endpoint}", timeout=30)
            
        error_message = handle_api_error(response)
        if error_message:
            return {"error": error_message}
        return response.json()
    except requests.exceptions.RequestException as e:
        return {"error": f"ë°±ì—”ë“œ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}"}

def generate_text(prompt, model_key, streaming_mode):
    """'/generate' ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    if not prompt:
        return "ì˜¤ë¥˜: í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", {"error": "Prompt is empty"}
    
    payload = {"prompt": prompt, "stream": streaming_mode}
    if model_key and model_key != "ê¸°ë³¸ ëª¨ë¸":
        payload["model_key"] = model_key

    if streaming_mode:
        # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ
        try:
            response = requests.post(
                f"{API_URL}/generate", 
                json=payload, 
                stream=True,
                headers={'Accept': 'text/event-stream'},
                timeout=300
            )
            
            if response.status_code != 200:
                return f"ì˜¤ë¥˜: HTTP {response.status_code}", {"error": "Stream failed"}
            
            full_text = ""
            token_count = 0
            
            for line in response.iter_lines(decode_unicode=True):
                if line and line.startswith('data: '):
                    try:
                        data_str = line[6:]  # 'data: ' ì œê±°
                        data = json.loads(data_str)
                        if 'error' in data:
                            return data['error'], {"error": data['error']}
                        if 'content' in data and data['content']:
                            full_text += data['content']
                            token_count += 1
                        if data.get('done', False):
                            break
                    except json.JSONDecodeError:
                        continue
            
            return full_text, {"model_info": {"streaming": True, "complete": True, "tokens": token_count}}
            
        except Exception as e:
            return f"ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {str(e)}", {"error": str(e)}
    else:
        # ì¼ë°˜ ëª¨ë“œ
        result = make_api_call("generate", payload)
        
        if "error" in result:
            return result["error"], result
        else:
            return result.get("response", "ì‘ë‹µ ì—†ìŒ"), result.get("model_info", {})

def stream_generate_text_generator(payload):
    """ìŠ¤íŠ¸ë¦¬ë° í…ìŠ¤íŠ¸ ìƒì„± (generator)"""
    try:
        response = requests.post(
            f"{API_URL}/generate", 
            json=payload, 
            stream=True,
            headers={'Accept': 'text/event-stream'},
            timeout=300
        )
        
        if response.status_code != 200:
            yield f"ì˜¤ë¥˜: HTTP {response.status_code}", {"error": "Stream failed"}
            return
        
        full_text = ""
        
        for line in response.iter_lines(decode_unicode=True):
            if line and line.startswith('data: '):
                try:
                    data_str = line[6:]  # 'data: ' ì œê±°
                    data = json.loads(data_str)
                    if 'error' in data:
                        yield data['error'], {"error": data['error']}
                        return
                    if 'content' in data and data['content']:
                        full_text += data['content']
                        # ì‹¤ì‹œê°„ìœ¼ë¡œ ëˆ„ì ëœ í…ìŠ¤íŠ¸ ì¶œë ¥
                        yield full_text, {"model_info": {"streaming": True, "tokens_so_far": len(full_text.split())}}
                    if data.get('done', False):
                        # ìµœì¢… ì™„ì„±ëœ í…ìŠ¤íŠ¸
                        yield full_text, {"model_info": {"streaming": True, "complete": True}}
                        return
                except json.JSONDecodeError:
                    continue
        
    except Exception as e:
        yield f"ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {str(e)}", {"error": str(e)}

def stream_generate_text(payload):
    """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜"""
    full_text = ""
    model_info = {}
    
    for text, info in stream_generate_text_generator(payload):
        full_text = text
        model_info = info
    
    return full_text, model_info

def stream_generate_text_with_progress(payload):
    """ì§„í–‰ìƒí™©ì„ í‘œì‹œí•˜ë©´ì„œ ìŠ¤íŠ¸ë¦¬ë° í…ìŠ¤íŠ¸ ìƒì„±"""
    import time
    try:
        response = requests.post(
            f"{API_URL}/generate", 
            json=payload, 
            stream=True,
            headers={'Accept': 'text/event-stream'},
            timeout=300
        )
        
        if response.status_code != 200:
            return f"ì˜¤ë¥˜: HTTP {response.status_code}", {"error": "Stream failed"}
        
        full_text = ""
        last_update_time = time.time()
        
        for line in response.iter_lines(decode_unicode=True):
            if line and line.startswith('data: '):
                try:
                    data_str = line[6:]  # 'data: ' ì œê±°
                    data = json.loads(data_str)
                    if 'error' in data:
                        return data['error'], {"error": data['error']}
                    if 'content' in data and data['content']:
                        full_text += data['content']
                        # ì§§ì€ ì§€ì—°ì„ í†µí•´ ì‹¤ì‹œê°„ íš¨ê³¼ ì‹œë®¬ë ˆì´ì…˜
                        current_time = time.time()
                        if current_time - last_update_time > 0.05:  # 50msë§ˆë‹¤ ì—…ë°ì´íŠ¸
                            time.sleep(0.01)
                            last_update_time = current_time
                    if data.get('done', False):
                        break
                except json.JSONDecodeError:
                    continue
        
        return full_text, {"model_info": {"streaming": True, "complete": True, "length": len(full_text)}}
        
    except Exception as e:
        return f"ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {str(e)}", {"error": str(e)}

def chat_with_bot(message, history, model_key):
    """'/chat' ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    payload = {"message": message}
    if model_key and model_key != "ê¸°ë³¸ ëª¨ë¸":
        payload["model_key"] = model_key

    result = make_api_call("chat", payload)
    if "error" in result:
        return result["error"]
        
    return result.get("response", "ì‘ë‹µ ì—†ìŒ")

def rag_query(question, model_key):
    """'/rag' ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    if not question:
        return "ì˜¤ë¥˜: ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", "", {"error": "Question is empty"}

    payload = {"question": question}
    if model_key and model_key != "ê¸°ë³¸ ëª¨ë¸":
        payload["model_key"] = model_key

    result = make_api_call("rag", payload)
    if "error" in result:
        return result["error"], "", result

    docs = result.get("relevant_documents", [])
    doc_str = ""
    if docs:
        for doc in docs:
            doc_str += f"### ğŸ“„ [{doc.get('title', 'ì¶œì²˜ ì—†ìŒ')}]({doc.get('source', '#')})\n> {doc.get('content', '')}\n\n---\n"
    else:
        doc_str = "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
    return result.get("response", "ì‘ë‹µ ì—†ìŒ"), doc_str, result.get("model_info", {})

def update_rag_news(query, max_results):
    """'/rag/update-news' ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•˜ì—¬ DBë¥¼ ìµœì‹  ë‰´ìŠ¤ë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    if not query:
        return "ì˜¤ë¥˜: ë‰´ìŠ¤ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    gr.Info(f"'{query}' ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ {max_results}ê°œë¥¼ ê²€ìƒ‰í•˜ì—¬ DB ì—…ë°ì´íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
    
    payload = {"query": query, "max_results": int(max_results)}
    result = make_api_call("rag/update-news", payload)
    
    if "error" in result:
        gr.Error("ì—…ë°ì´íŠ¸ ì‹¤íŒ¨!")
        return result["error"]
    
    gr.Info("ì—…ë°ì´íŠ¸ ì„±ê³µ!")
    return result.get("message", "ì•Œ ìˆ˜ ì—†ëŠ” ì‘ë‹µ")

def update_model_list():
    """UIê°€ ë¡œë“œë  ë•Œ ì„œë²„ì—ì„œ ëª¨ë¸ ëª©ë¡ì„ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    logger.info("UI: ëª¨ë¸ ëª©ë¡ì„ ì„œë²„ì—ì„œ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    
    # ì •ì  ëª¨ë¸ ëª©ë¡ (ì„œë²„ì™€ ë™ê¸°í™”)
    default_models = ["qwen2.5-7b", "llama3.1-8b", "gemma-3-4b"]
    choices = ["ê¸°ë³¸ ëª¨ë¸"] + default_models
    
    try:
        response = requests.get(f"{API_URL}/models", timeout=5)
        if response.status_code == 200:
            server_models = list(response.json().get("supported_models", {}).keys())
            if server_models:
                choices = ["ê¸°ë³¸ ëª¨ë¸"] + server_models
                logger.info(f"UI: ì„œë²„ì—ì„œ ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ: {server_models}")
            else:
                logger.warning("UI: ì„œë²„ì—ì„œ ë¹ˆ ëª¨ë¸ ëª©ë¡ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª©ë¡ ì‚¬ìš©")
        else:
            logger.warning(f"UI: ì„œë²„ ì‘ë‹µ ì‹¤íŒ¨ (HTTP {response.status_code}). ê¸°ë³¸ ëª©ë¡ ì‚¬ìš©")
    except requests.exceptions.RequestException as e:
        logger.warning(f"UI: ì„œë²„ ì—°ê²° ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë¸ ëª©ë¡ ì‚¬ìš©: {e}")
    
    logger.info(f"UI: ìµœì¢… ëª¨ë¸ ì„ íƒì§€: {choices}")
    return (
        gr.Dropdown(choices=choices, value="ê¸°ë³¸ ëª¨ë¸"),
        gr.Dropdown(choices=choices, value="ê¸°ë³¸ ëª¨ë¸"), 
        gr.Dropdown(choices=choices, value="ê¸°ë³¸ ëª¨ë¸")
    )

# --- Gradio UI êµ¬ì„± ---
with gr.Blocks(theme=gr.themes.Soft(), title="LLM ì„œë²„ UI") as gradio_ui:
    gr.Markdown("# ğŸ¤– LLM FastAPI ì„œë²„ UI")
    gr.Markdown("Gradio ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ ì„œë²„ì˜ LLM ê¸°ëŠ¥ì„ ì‰½ê²Œ ì‚¬ìš©í•´ë³´ì„¸ìš”.")
    
    with gr.Tabs():
        # 1. í…ìŠ¤íŠ¸ ìƒì„± íƒ­
        with gr.TabItem("ğŸ“ í…ìŠ¤íŠ¸ ìƒì„±"):
            gr.Markdown("### ğŸ’¡ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì„ ì›í•˜ì‹œë©´ [ì „ìš© ìŠ¤íŠ¸ë¦¬ë° í˜ì´ì§€](/stream)ë¥¼ ì´ìš©í•´ì£¼ì„¸ìš”!")
            with gr.Row():
                with gr.Column(scale=2):
                    gen_prompt = gr.Textbox(lines=5, label="í”„ë¡¬í”„íŠ¸", placeholder="ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ì— ëŒ€í•´ ì§§ì€ ê¸€ì„ ì¨ì¤˜.")
                    gen_model_select = gr.Dropdown(
                        label="ëª¨ë¸ ì„ íƒ", 
                        choices=["ê¸°ë³¸ ëª¨ë¸", "qwen2.5-7b", "llama3.1-8b", "gemma-3-4b"],
                        value="ê¸°ë³¸ ëª¨ë¸"
                    )
                    gen_streaming = gr.Checkbox(label="ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ (ì™„ì„± í›„ ì¼ê´„ í‘œì‹œ)", value=False)
                    gen_button = gr.Button("ìƒì„±í•˜ê¸°", variant="primary")
                with gr.Column(scale=3):
                    gen_output = gr.Textbox(lines=10, label="ìƒì„±ëœ í…ìŠ¤íŠ¸", interactive=False)
                    gen_model_info = gr.JSON(label="ì‚¬ìš©ëœ ëª¨ë¸ ì •ë³´ / ì˜¤ë¥˜ ìƒì„¸")

        # 2. ì±„íŒ… íƒ­
        with gr.TabItem("ğŸ’¬ ì±„íŒ…"):
            chat_model_select = gr.Dropdown(
                label="ì±„íŒ… ëª¨ë¸ ì„ íƒ", 
                choices=["ê¸°ë³¸ ëª¨ë¸", "qwen2.5-7b", "llama3.1-8b", "gemma-3-4b"],
                value="ê¸°ë³¸ ëª¨ë¸"
            )
            gr.ChatInterface(
                fn=chat_with_bot,
                additional_inputs=[chat_model_select],
                chatbot=gr.Chatbot(height=400, label="ì±„íŒ…ì°½", type="messages"),
                textbox=gr.Textbox(placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", label="ì…ë ¥"),
                submit_btn="ë³´ë‚´ê¸°",
            )

        # 3. RAG ì§ˆì˜ì‘ë‹µ íƒ­
        with gr.TabItem("ğŸ“š RAG ì§ˆì˜ì‘ë‹µ"):
            with gr.Accordion("ìµœì‹  ë‰´ìŠ¤ë¡œ DB ì—…ë°ì´íŠ¸", open=False):
                with gr.Row():
                    news_query = gr.Textbox(label="ë‰´ìŠ¤ ê²€ìƒ‰ì–´", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì AI")
                    news_max_results = gr.Slider(minimum=1, maximum=20, value=5, step=1, label="ìµœëŒ€ ê²€ìƒ‰ ê¸°ì‚¬ ìˆ˜")
                update_button = gr.Button("DB ì—…ë°ì´íŠ¸ ì‹¤í–‰", variant="primary")
                update_status = gr.Textbox(label="ì—…ë°ì´íŠ¸ ê²°ê³¼", interactive=False)
            
            gr.Markdown("---")
            
            with gr.Row():
                with gr.Column(scale=2):
                    rag_question = gr.Textbox(lines=2, label="ì§ˆë¬¸", placeholder="ì‚¼ì„±ì „ìì˜ ìµœì‹  AI ê¸°ìˆ ì— ëŒ€í•´ ì•Œë ¤ì¤˜.")
                    rag_model_select = gr.Dropdown(
                        label="ëª¨ë¸ ì„ íƒ", 
                        choices=["ê¸°ë³¸ ëª¨ë¸", "qwen2.5-7b", "llama3.1-8b", "gemma-3-4b"],
                        value="ê¸°ë³¸ ëª¨ë¸"
                    )
                    rag_button = gr.Button("ì§ˆë¬¸í•˜ê¸°", variant="primary")
                with gr.Column(scale=3):
                    rag_answer = gr.Textbox(lines=5, label="ë‹µë³€", interactive=False)
                    rag_model_info_output = gr.JSON(label="ì‚¬ìš©ëœ ëª¨ë¸ ì •ë³´ / ì˜¤ë¥˜ ìƒì„¸")
            rag_docs = gr.Markdown(label="ì°¸ê³  ë¬¸ì„œ")

    # --- ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ---
    gen_button.click(fn=generate_text, inputs=[gen_prompt, gen_model_select, gen_streaming], outputs=[gen_output, gen_model_info])
    rag_button.click(fn=rag_query, inputs=[rag_question, rag_model_select], outputs=[rag_answer, rag_docs, rag_model_info_output])
    update_button.click(fn=update_rag_news, inputs=[news_query, news_max_results], outputs=update_status)

if __name__ == "__main__":
    gradio_ui.launch()
