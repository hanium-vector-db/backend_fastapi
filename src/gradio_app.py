import gradio as gr
import requests
import json
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì„œë²„ ì£¼ì†Œ
API_URL = "http://127.0.0.1:8000/api/v1"

def handle_api_error(response):
    """
    API ì‘ë‹µ ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•˜ê³  ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì„±ê³µ ì‹œ Noneì„, ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ë¬¸ìì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if response.status_code >= 400:
        try:
            detail = response.json().get("detail", "ì•Œ ìˆ˜ ì—†ëŠ” ì„œë²„ ì˜¤ë¥˜")
            return f"**ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ (HTTP {response.status_code})**\n\n**ì˜¤ë¥˜ ë‚´ìš©:**\n{detail}\n\n**ì„œë²„ ì‘ë‹µ ì›ë¬¸:**\n```\n{response.text}\n```"
        except json.JSONDecodeError:
            return f"**ì„œë²„ì—ì„œ ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ (HTTP {response.status_code})**\n\n**ì„œë²„ ì‘ë‹µ ì›ë¬¸:**\n```\n{response.text}\n```"
    return None

def make_api_call(endpoint, payload, method="post"):
    """ì¤‘ë³µë˜ëŠ” API í˜¸ì¶œ ë¡œì§ì„ ì²˜ë¦¬í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    try:
        if method.lower() == "post":
            response = requests.post(f"{API_URL}/{endpoint}", json=payload, timeout=300) # íƒ€ì„ì•„ì›ƒ ì¦ê°€
        else:
            response = requests.get(f"{API_URL}/{endpoint}", timeout=30)
            
        error_message = handle_api_error(response)
        if error_message:
            return {"error": error_message}
        return response.json()
    except requests.exceptions.RequestException as e:
        return {"error": f"ë°±ì—”ë“œ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}"}

def generate_text(prompt, model_key):
    """'/generate' ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    if not prompt:
        return "ì˜¤ë¥˜: í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", {"error": "Prompt is empty"}
    
    payload = {"prompt": prompt}
    if model_key and model_key != "ê¸°ë³¸ ëª¨ë¸":
        payload["model_key"] = model_key

    result = make_api_call("generate", payload)
    if "error" in result:
        return result["error"], result
    
    return result.get("response", "ì‘ë‹µ ì—†ìŒ"), result.get("model_info", {})

def chat_with_bot(message, history, model_key):
    """'/chat' ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    payload = {"message": message}
    if model_key and model_key != "ê¸°ë³¸ ëª¨ë¸":
        payload["model_key"] = model_key

    result = make_api_call("chat", payload)
    if "error" in result:
        return result["error"]
        
    return result.get("response", "ì‘ë‹µ ì—†ìŒ")

def rag_query(question, model_key):
    """'/rag' ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    if not question:
        return "ì˜¤ë¥˜: ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", "", {"error": "Question is empty"}

    payload = {"question": question}
    if model_key and model_key != "ê¸°ë³¸ ëª¨ë¸":
        payload["model_key"] = model_key

    result = make_api_call("rag", payload)
    if "error" in result:
        return result["error"], "", result

    docs = result.get("relevant_documents", [])
    doc_str = ""
    if docs:
        for doc in docs:
            doc_str += f"### ğŸ“„ [{doc.get('title', 'ì¶œì²˜ ì—†ìŒ')}]({doc.get('source', '#')})\n> {doc.get('content', '')}\n\n---\n"
    else:
        doc_str = "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
    return result.get("response", "ì‘ë‹µ ì—†ìŒ"), doc_str, result.get("model_info", {})

def update_rag_news(query, max_results):
    """'/rag/update-news' ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•˜ì—¬ DBë¥¼ ìµœì‹  ë‰´ìŠ¤ë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    if not query:
        return "ì˜¤ë¥˜: ë‰´ìŠ¤ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    gr.Info(f"'{query}' ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ {max_results}ê°œë¥¼ ê²€ìƒ‰í•˜ì—¬ DB ì—…ë°ì´íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
    
    payload = {"query": query, "max_results": int(max_results)}
    result = make_api_call("rag/update-news", payload)
    
    if "error" in result:
        gr.Error("ì—…ë°ì´íŠ¸ ì‹¤íŒ¨!")
        return result["error"]
    
    gr.Info("ì—…ë°ì´íŠ¸ ì„±ê³µ!")
    return result.get("message", "ì•Œ ìˆ˜ ì—†ëŠ” ì‘ë‹µ")

def update_model_list():
    """UIê°€ ë¡œë“œë  ë•Œ ì„œë²„ì—ì„œ ëª¨ë¸ ëª©ë¡ì„ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    logger.info("UI: ëª¨ë¸ ëª©ë¡ì„ ì„œë²„ì—ì„œ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    try:
        response = requests.get(f"{API_URL}/models", timeout=10)
        response.raise_for_status()
        models = list(response.json().get("supported_models", {}).keys())
        choices = ["ê¸°ë³¸ ëª¨ë¸"] + models
        logger.info(f"UI: ëª¨ë¸ ëª©ë¡ ì—…ë°ì´íŠ¸ ì™„ë£Œ. ì°¾ì€ ëª¨ë¸: {models}")
        return gr.Dropdown(choices=choices, value="ê¸°ë³¸ ëª¨ë¸"), gr.Dropdown(choices=choices, value="ê¸°ë³¸ ëª¨ë¸"), gr.Dropdown(choices=choices, value="ê¸°ë³¸ ëª¨ë¸")
    except requests.exceptions.RequestException as e:
        logger.error(f"UI: ì„œë²„ì—ì„œ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        gr.Warning("ì„œë²„ì—ì„œ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë°±ì—”ë“œ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return gr.Dropdown(choices=["ê¸°ë³¸ ëª¨ë¸"], value="ê¸°ë³¸ ëª¨ë¸"), gr.Dropdown(choices=["ê¸°ë³¸ ëª¨ë¸"], value="ê¸°ë³¸ ëª¨ë¸"), gr.Dropdown(choices=["ê¸°ë³¸ ëª¨ë¸"], value="ê¸°ë³¸ ëª¨ë¸")

# --- Gradio UI êµ¬ì„± ---
with gr.Blocks(theme=gr.themes.Soft(), title="LLM ì„œë²„ UI") as gradio_ui:
    gr.Markdown("# ğŸ¤– LLM FastAPI ì„œë²„ UI")
    gr.Markdown("Gradio ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ ì„œë²„ì˜ LLM ê¸°ëŠ¥ì„ ì‰½ê²Œ ì‚¬ìš©í•´ë³´ì„¸ìš”.")
    
    with gr.Tabs():
        # 1. í…ìŠ¤íŠ¸ ìƒì„± íƒ­
        with gr.TabItem("ğŸ“ í…ìŠ¤íŠ¸ ìƒì„±"):
            with gr.Row():
                with gr.Column(scale=2):
                    gen_prompt = gr.Textbox(lines=5, label="í”„ë¡¬í”„íŠ¸", placeholder="ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ì— ëŒ€í•´ ì§§ì€ ê¸€ì„ ì¨ì¤˜.")
                    gen_model_select = gr.Dropdown(label="ëª¨ë¸ ì„ íƒ (UI ë¡œë”© ì‹œ ìë™ ì—…ë°ì´íŠ¸)")
                    gen_button = gr.Button("ìƒì„±í•˜ê¸°", variant="primary")
                with gr.Column(scale=3):
                    gen_output = gr.Textbox(lines=10, label="ìƒì„±ëœ í…ìŠ¤íŠ¸", interactive=False)
                    gen_model_info = gr.JSON(label="ì‚¬ìš©ëœ ëª¨ë¸ ì •ë³´ / ì˜¤ë¥˜ ìƒì„¸")

        # 2. ì±„íŒ… íƒ­
        with gr.TabItem("ğŸ’¬ ì±„íŒ…"):
            chat_model_select = gr.Dropdown(label="ì±„íŒ… ëª¨ë¸ ì„ íƒ (UI ë¡œë”© ì‹œ ìë™ ì—…ë°ì´íŠ¸)")
            gr.ChatInterface(
                fn=chat_with_bot,
                additional_inputs=[chat_model_select],
                chatbot=gr.Chatbot(height=400, label="ì±„íŒ…ì°½"),
                textbox=gr.Textbox(placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", label="ì…ë ¥"),
                submit_btn="ë³´ë‚´ê¸°",
            )

        # 3. RAG ì§ˆì˜ì‘ë‹µ íƒ­
        with gr.TabItem("ğŸ“š RAG ì§ˆì˜ì‘ë‹µ"):
            with gr.Accordion("ìµœì‹  ë‰´ìŠ¤ë¡œ DB ì—…ë°ì´íŠ¸", open=False):
                with gr.Row():
                    news_query = gr.Textbox(label="ë‰´ìŠ¤ ê²€ìƒ‰ì–´", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì AI")
                    news_max_results = gr.Slider(minimum=1, maximum=20, value=5, step=1, label="ìµœëŒ€ ê²€ìƒ‰ ê¸°ì‚¬ ìˆ˜")
                update_button = gr.Button("DB ì—…ë°ì´íŠ¸ ì‹¤í–‰", variant="primary")
                update_status = gr.Textbox(label="ì—…ë°ì´íŠ¸ ê²°ê³¼", interactive=False)
            
            gr.Markdown("---")
            
            with gr.Row():
                with gr.Column(scale=2):
                    rag_question = gr.Textbox(lines=2, label="ì§ˆë¬¸", placeholder="ì‚¼ì„±ì „ìì˜ ìµœì‹  AI ê¸°ìˆ ì— ëŒ€í•´ ì•Œë ¤ì¤˜.")
                    rag_model_select = gr.Dropdown(label="ëª¨ë¸ ì„ íƒ (UI ë¡œë”© ì‹œ ìë™ ì—…ë°ì´íŠ¸)")
                    rag_button = gr.Button("ì§ˆë¬¸í•˜ê¸°", variant="primary")
                with gr.Column(scale=3):
                    rag_answer = gr.Textbox(lines=5, label="ë‹µë³€", interactive=False)
                    rag_model_info_output = gr.JSON(label="ì‚¬ìš©ëœ ëª¨ë¸ ì •ë³´ / ì˜¤ë¥˜ ìƒì„¸")
            rag_docs = gr.Markdown(label="ì°¸ê³  ë¬¸ì„œ")

    # --- ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ---
    gen_button.click(fn=generate_text, inputs=[gen_prompt, gen_model_select], outputs=[gen_output, gen_model_info])
    rag_button.click(fn=rag_query, inputs=[rag_question, rag_model_select], outputs=[rag_answer, rag_docs, rag_model_info_output])
    update_button.click(fn=update_rag_news, inputs=[news_query, news_max_results], outputs=update_status)
    
    # UIê°€ ë¸Œë¼ìš°ì €ì— ë¡œë“œë  ë•Œ, update_model_list í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ì—¬ ë“œë¡­ë‹¤ìš´ ë©”ë‰´ë¥¼ ì±„ì›ë‹ˆë‹¤.
    gradio_ui.load(fn=update_model_list, inputs=None, outputs=[gen_model_select, chat_model_select, rag_model_select])

if __name__ == "__main__":
    gradio_ui.launch()
