"""
Hugging Face í† í° ì„¤ì • ë° Llama ì ‘ê·¼ ê¶Œí•œ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸
"""
import os
import sys
from huggingface_hub import login, whoami

def setup_huggingface_token():
    """Hugging Face í† í° ì„¤ì •"""
    print("ğŸ¤– Hugging Face í† í° ì„¤ì •")
    print("="*50)
    
    # ê¸°ì¡´ í† í° í™•ì¸
    token = os.getenv('HUGGINGFACE_TOKEN') or os.getenv('HF_TOKEN')
    
    if token:
        print(f"âœ… í™˜ê²½ë³€ìˆ˜ì—ì„œ í† í° ë°œê²¬: {token[:10]}...")
        try:
            user_info = whoami(token=token)
            print(f"âœ… ì¸ì¦ëœ ì‚¬ìš©ì: {user_info['name']}")
            return token
        except Exception as e:
            print(f"âŒ í† í° ì¸ì¦ ì‹¤íŒ¨: {e}")
    else:
        print("âš ï¸ í™˜ê²½ë³€ìˆ˜ì— í† í°ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # í† í° ì…ë ¥ ë°›ê¸°
    print("\nğŸ“ Hugging Face í† í°ì„ ì…ë ¥í•˜ì„¸ìš”:")
    print("1. https://huggingface.co/settings/tokens ì—ì„œ í† í° ìƒì„±")
    print("2. 'Read' ê¶Œí•œìœ¼ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤")
    print("3. ì•„ë˜ì— í† í°ì„ ì…ë ¥í•˜ì„¸ìš”:")
    
    new_token = input("\nHugging Face Token: ").strip()
    
    if not new_token:
        print("âŒ í† í°ì´ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    try:
        login(token=new_token)
        user_info = whoami(token=new_token)
        print(f"âœ… ë¡œê·¸ì¸ ì„±ê³µ: {user_info['name']}")
        
        # í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •
        os.environ['HUGGINGFACE_TOKEN'] = new_token
        
        return new_token
    except Exception as e:
        print(f"âŒ í† í° ì¸ì¦ ì‹¤íŒ¨: {e}")
        return None

def check_llama_access(token):
    """Llama ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œ í™•ì¸"""
    print("\nğŸ¦™ Llama 3.1 ì ‘ê·¼ ê¶Œí•œ í™•ì¸")
    print("="*50)
    
    try:
        from transformers import AutoTokenizer
        
        model_id = "meta-llama/Meta-Llama-3.1-8B-Instruct"
        print(f"ğŸ” ëª¨ë¸ ì ‘ê·¼ í…ŒìŠ¤íŠ¸: {model_id}")
        
        tokenizer = AutoTokenizer.from_pretrained(
            model_id,
            token=token,
            cache_dir="/home/ubuntu_euphoria/.huggingface_models"
        )
        
        print("âœ… Llama 3.1 ì ‘ê·¼ ê¶Œí•œ í™•ì¸ë¨!")
        return True
        
    except Exception as e:
        error_msg = str(e)
        print(f"âŒ Llama 3.1 ì ‘ê·¼ ì‹¤íŒ¨: {error_msg}")
        
        if "gated repo" in error_msg or "restricted" in error_msg:
            print("\nğŸ“‹ í•´ê²° ë°©ë²•:")
            print("1. https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct ë°©ë¬¸")
            print("2. 'Request access to this model' í´ë¦­")
            print("3. Meta AIì˜ ë¼ì´ì„ ìŠ¤ ë™ì˜")
            print("4. ìŠ¹ì¸ê¹Œì§€ ëª‡ ë¶„~ëª‡ ì‹œê°„ ì†Œìš”")
            
        return False

def suggest_alternatives():
    """ëŒ€ì²´ ëª¨ë¸ ì œì•ˆ"""
    print("\nğŸ”„ ëŒ€ì²´ ëª¨ë¸ ì˜µì…˜")
    print("="*50)
    
    alternatives = [
        {
            "name": "Microsoft Phi-3.5 Mini",
            "model_id": "microsoft/Phi-3.5-mini-instruct",
            "description": "ê³ ì„±ëŠ¥ ì†Œí˜• ëª¨ë¸, ì ‘ê·¼ ì œí•œ ì—†ìŒ"
        },
        {
            "name": "Mistral 7B v0.3",
            "model_id": "mistralai/Mistral-7B-Instruct-v0.3",
            "description": "Mistral AIì˜ ê³ ì„±ëŠ¥ ëª¨ë¸"
        },
        {
            "name": "CodeLlama 7B",
            "model_id": "codellama/CodeLlama-7b-Instruct-hf",
            "description": "ì½”ë”© íŠ¹í™” Llama ê¸°ë°˜ ëª¨ë¸"
        }
    ]
    
    for i, alt in enumerate(alternatives, 1):
        print(f"{i}. {alt['name']}")
        print(f"   ëª¨ë¸ ID: {alt['model_id']}")
        print(f"   ì„¤ëª…: {alt['description']}")
        print()
    
    choice = input("ëŒ€ì²´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (1-3, ë˜ëŠ” Enterë¡œ ê±´ë„ˆë›°ê¸°): ").strip()
    
    if choice in ['1', '2', '3']:
        selected = alternatives[int(choice) - 1]
        print(f"\nâœ… ì„ íƒëœ ëŒ€ì²´ ëª¨ë¸: {selected['name']}")
        print(f"ğŸ“ llm_handler.py ì—ì„œ ëª¨ë¸ IDë¥¼ ë‹¤ìŒìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”:")
        print(f"   {selected['model_id']}")
        return selected
    
    return None

def main():
    print("ğŸ¤– LLM ì„œë²„ Hugging Face ì„¤ì •")
    print("="*60)
    
    # 1. í† í° ì„¤ì •
    token = setup_huggingface_token()
    if not token:
        print("âŒ í† í° ì„¤ì •ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    # 2. Llama ì ‘ê·¼ ê¶Œí•œ í™•ì¸
    has_llama_access = check_llama_access(token)
    
    # 3. ì ‘ê·¼ ê¶Œí•œì´ ì—†ìœ¼ë©´ ëŒ€ì²´ ëª¨ë¸ ì œì•ˆ
    if not has_llama_access:
        suggest_alternatives()
    
    print("\n" + "="*60)
    print("ğŸ‰ ì„¤ì • ì™„ë£Œ! ì´ì œ ì„œë²„ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
    print("   python src/main.py")
    print("="*60)

if __name__ == "__main__":
    main()