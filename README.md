# LLM FastAPI ì„œë²„

Retrieval-Augmented Generation (RAG) ê¸°ëŠ¥ì„ ê°–ì¶˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ë°°í¬ë¥¼ ìœ„í•œ í”„ë¡œë•ì…˜ ì¤€ë¹„ ì™„ë£Œ FastAPI ì„œë²„ì…ë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” ë¬¸ì„œ ê²€ìƒ‰, ì„ë² ë”©, ì±„íŒ… ê¸°ëŠ¥ê³¼ ê°™ì€ ê³ ê¸‰ ê¸°ëŠ¥ìœ¼ë¡œ ì‚¬ìš©ì ì •ì˜ LLMì„ ì œê³µí•˜ëŠ” í¬ê´„ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥

- **ì‚¬ìš©ì ì •ì˜ LLM ë°°í¬**: 4bit ì–‘ìí™”ë¥¼ í†µí•œ Hugging Face ëª¨ë¸ ì§€ì›
- **RAG (ê²€ìƒ‰ ì¦ê°• ìƒì„±)**: ì§€ëŠ¥ì ì¸ ë¬¸ì„œ ê²€ìƒ‰ ë° ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ì‘ë‹µ
- **ì„ë² ë”© ìƒì„±**: BGE-M3 ëª¨ë¸ì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
- **ì±„íŒ… ì¸í„°í˜ì´ìŠ¤**: ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•˜ëŠ” ëŒ€í™”í˜• ì±„íŒ… ê¸°ëŠ¥
- **RESTful API**: ìë™ OpenAPI ë¬¸ì„œí™”ê°€ í¬í•¨ëœ ì˜ ë¬¸ì„œí™”ëœ API ì—”ë“œí¬ì¸íŠ¸
- **Docker ì§€ì›**: ì‰¬ìš´ í™•ì¥ì„ ìœ„í•œ ì»¨í…Œì´ë„ˆí™”ëœ ë°°í¬
- **í”„ë¡œë•ì…˜ ì¤€ë¹„**: í¬ê´„ì ì¸ ë¡œê¹…, ì˜¤ë¥˜ ì²˜ë¦¬ ë° ìƒíƒœ í™•ì¸

## ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
llm-fastapi-server/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                    # FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì 
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ routes.py              # API ì—”ë“œí¬ì¸íŠ¸ ì •ì˜
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm_handler.py         # LLM ëª¨ë¸ ê´€ë¦¬
â”‚   â”‚   â””â”€â”€ embedding_handler.py   # ì„ë² ë”© ëª¨ë¸ ê´€ë¦¬
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ rag_service.py         # RAG ê¸°ëŠ¥
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py              # ì„¤ì • ê´€ë¦¬
â”‚   â”‚   â””â”€â”€ logger.py              # ë¡œê¹… ì„¤ì •
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ helpers.py             # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ llm_setup.ipynb            # ëª¨ë¸ ì„¤ì • ë° í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ rag_development.ipynb      # RAG ê°œë°œ ë…¸íŠ¸ë¶
â”œâ”€â”€ data/
â”‚   â””â”€â”€ vector_db/                 # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ì†Œ
â”œâ”€â”€ requirements.txt               # Python ì˜ì¡´ì„±
â”œâ”€â”€ Dockerfile                     # Docker ì„¤ì •
â”œâ”€â”€ docker-compose.yml             # Docker Compose ì„¤ì •
â””â”€â”€ README.md                      # í”„ë¡œì íŠ¸ ë¬¸ì„œ
```

## ğŸ”§ ì„¤ì¹˜

### ì‚¬ì „ ìš”êµ¬ì‚¬í•­

- Python 3.11+
- CUDA í˜¸í™˜ GPU (ëŒ€í˜• ëª¨ë¸ì— ê¶Œì¥)
- Git

### ì„¤ì •

1. **ì €ì¥ì†Œ ë³µì œ**
   ```bash
   git clone https://github.com/hanium-vector-db/AWS_LOCAL_LLM.git
   cd AWS_LOCAL_LLM
   ```

2. **ê°€ìƒ í™˜ê²½ ìƒì„±**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   ```

3. **ì˜ì¡´ì„± ì„¤ì¹˜**
   ```bash
   pip install -r requirements.txt
   ```

4. **Hugging Face í† í° ì„¤ì •**
   ```bash
   # í™˜ê²½ ë³€ìˆ˜ë¡œ Hugging Face í† í° ì„¤ì •
   export HUGGINGFACE_TOKEN="your_token_here"
   ```

## ğŸš€ ì‚¬ìš©ë²•

### ì„œë²„ ì‹¤í–‰

#### ë°©ë²• 1: Python ì§ì ‘ ì‹¤í–‰
```bash
cd src
python main.py
```

#### ë°©ë²• 2: uvicorn ì‚¬ìš©
```bash
uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
```

#### ë°©ë²• 3: Docker ì‚¬ìš©
```bash
# Docker Composeë¡œ ë¹Œë“œ ë° ì‹¤í–‰
docker-compose up -d
```

### API ì—”ë“œí¬ì¸íŠ¸

ì„œë²„ê°€ ì‹¤í–‰ë˜ë©´ ëŒ€í™”í˜• API ë¬¸ì„œì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

#### ì‚¬ìš© ê°€ëŠ¥í•œ ì—”ë“œí¬ì¸íŠ¸:

| ì—”ë“œí¬ì¸íŠ¸ | ë©”ì†Œë“œ | ì„¤ëª… |
|-----------|--------|------|
| `/` | GET | í™˜ì˜ ë©”ì‹œì§€ ë° ì—”ë“œí¬ì¸íŠ¸ ê°œìš” |
| `/api/v1/health` | GET | ìƒíƒœ í™•ì¸ ë° ì„œë¹„ìŠ¤ ìƒíƒœ |
| `/api/v1/generate` | POST | LLMì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ìƒì„± |
| `/api/v1/chat` | POST | LLMê³¼ ì±„íŒ… |
| `/api/v1/embed` | POST | í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± |
| `/api/v1/rag` | POST | RAG ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ |

### API í˜¸ì¶œ ì˜ˆì‹œ

#### í…ìŠ¤íŠ¸ ìƒì„±
```bash
curl -X POST "http://localhost:8000/api/v1/generate" \
     -H "Content-Type: application/json" \
     -d '{"prompt": "ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”", "max_length": 512}'
```

#### ì±„íŒ…
```bash
curl -X POST "http://localhost:8000/api/v1/chat" \
     -H "Content-Type: application/json" \
     -d '{"message": "ë¨¸ì‹ ëŸ¬ë‹ì´ ë¬´ì—‡ì¸ê°€ìš”?"}'
```

#### RAG ì§ˆì˜
```bash
curl -X POST "http://localhost:8000/api/v1/rag" \
     -H "Content-Type: application/json" \
     -d '{"question": "íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì´ ë¬´ì—‡ì¸ê°€ìš”?"}'
```

#### ì„ë² ë”© ìƒì„±
```bash
curl -X POST "http://localhost:8000/api/v1/embed" \
     -H "Content-Type: application/json" \
     -d '{"text": "ì„ë² ë”©ì„ ìœ„í•œ ìƒ˜í”Œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤"}'
```

## ğŸ”§ ì„¤ì •

### í™˜ê²½ ë³€ìˆ˜

| ë³€ìˆ˜ | ì„¤ëª… | ê¸°ë³¸ê°’ |
|------|------|--------|
| `HUGGINGFACE_TOKEN` | Hugging Face API í† í° | í•„ìˆ˜ |
| `MODEL_ID` | LLM ëª¨ë¸ ì‹ë³„ì | `Qwen/Qwen2.5-1.5B-Instruct` |
| `EMBEDDING_MODEL` | ì„ë² ë”© ëª¨ë¸ ì´ë¦„ | `BAAI/bge-m3` |
| `MAX_TOKENS` | ìµœëŒ€ ìƒì„± í† í° ìˆ˜ | `512` |
| `TEMPERATURE` | ìƒì„± ì˜¨ë„ | `0.7` |

### ëª¨ë¸ ì„¤ì •

ì„œë²„ëŠ” ë‹¤ì–‘í•œ Hugging Face ëª¨ë¸ì„ ì§€ì›í•©ë‹ˆë‹¤:

- **ì†Œí˜• ëª¨ë¸ (1B-3B)**: `Qwen/Qwen2.5-1.5B-Instruct`, `meta-llama/Llama-3.2-1B-Instruct`
- **ì¤‘í˜• ëª¨ë¸ (7B-13B)**: `meta-llama/Llama-2-7b-chat-hf`, `mistralai/Mistral-7B-Instruct-v0.1`
- **ëŒ€í˜• ëª¨ë¸ (30B+)**: ë©€í‹° GPU ì„¤ì • í•„ìš”

## ğŸ“Š ì„±ëŠ¥

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

| ëª¨ë¸ í¬ê¸° | RAM | GPU ë©”ëª¨ë¦¬ | ê¶Œì¥ GPU |
|-----------|-----|-----------|----------|
| 1B-3B | 8GB | 4GB | GTX 1660, RTX 3060 |
| 7B-13B | 16GB | 8GB | RTX 3080, RTX 4070 |
| 30B+ | 32GB | 24GB+ | RTX 4090, A100 |

### ìµœì í™” ê¸°ëŠ¥

- **4bit ì–‘ìí™”**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ~75% ê°ì†Œ
- **ì§€ì—° ë¡œë”©**: ì²˜ìŒ ì ‘ê·¼ ì‹œì—ë§Œ ëª¨ë¸ ë¡œë“œ
- **íš¨ìœ¨ì ì¸ ìºì‹±**: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì§€ì†ì„±
- **ë¹„ë™ê¸° ì²˜ë¦¬**: ë¸”ë¡œí‚¹ë˜ì§€ ì•ŠëŠ” API ì‘ë‹µ

## ğŸ§ª ê°œë°œ

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
# ê°œë°œ ë…¸íŠ¸ë¶ ì‹¤í–‰
jupyter lab notebooks/
```

### ìƒˆ ëª¨ë¸ ì¶”ê°€

1. ìƒˆ ëª¨ë¸ ì„¤ì •ìœ¼ë¡œ `llm_handler.py` ì—…ë°ì´íŠ¸
2. ìƒˆ ì˜ì¡´ì„±ì´ í•„ìš”í•œ ê²½ìš° `requirements.txt` ìˆ˜ì •
3. ì œê³µëœ ë…¸íŠ¸ë¶ìœ¼ë¡œ í…ŒìŠ¤íŠ¸

## ğŸ“¦ Docker ë°°í¬

### ì´ë¯¸ì§€ ë¹Œë“œ
```bash
docker build -t llm-fastapi-server .
```

### ì»¨í…Œì´ë„ˆ ì‹¤í–‰
```bash
docker run -p 8000:8000 \
  -e HUGGINGFACE_TOKEN="your_token" \
  -v $(pwd)/data:/app/data \
  llm-fastapi-server
```

### í”„ë¡œë•ì…˜ ë°°í¬
```bash
docker-compose up -d
```

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. ì €ì¥ì†Œ í¬í¬
2. ê¸°ëŠ¥ ë¸Œëœì¹˜ ìƒì„± (`git checkout -b feature/amazing-feature`)
3. ë³€ê²½ì‚¬í•­ ì»¤ë°‹ (`git commit -m 'Add amazing feature'`)
4. ë¸Œëœì¹˜ì— í‘¸ì‹œ (`git push origin feature/amazing-feature`)
5. Pull Request ì—´ê¸°

## ğŸ“ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë¼ì´ì„ ìŠ¤ê°€ ë¶€ì—¬ë©ë‹ˆë‹¤ - ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ™ ê°ì‚¬ì˜ ë§

- ìš°ìˆ˜í•œ ëª¨ë¸ í˜¸ìŠ¤íŒ…ì„ ì œê³µí•˜ëŠ” [Hugging Face](https://huggingface.co/)
- ë†€ë¼ìš´ ì›¹ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•˜ëŠ” [FastAPI](https://fastapi.tiangolo.com/)
- RAG ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” [LangChain](https://langchain.com/)
- ì„ë² ë”© ëª¨ë¸ì„ ì œê³µí•˜ëŠ” [Sentence Transformers](https://www.sbert.net/)

## ğŸ“ ì§€ì›

ì§ˆë¬¸ ë° ì§€ì›:

- ì´ ì €ì¥ì†Œì—ì„œ ì´ìŠˆ ìƒì„±
- ì„œë²„ ì‹¤í–‰ ì‹œ [ë¬¸ì„œ](http://localhost:8000/docs) í™•ì¸
- `notebooks/` ë””ë ‰í† ë¦¬ì˜ ì˜ˆì œ ë…¸íŠ¸ë¶ ê²€í† 

---

**ì°¸ê³ **: ì´ ì„œë²„ëŠ” êµìœ¡ ë° ê°œë°œ ëª©ì ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œë•ì…˜ ë°°í¬ì˜ ê²½ìš° ì ì ˆí•œ ë³´ì•ˆ ì¡°ì¹˜, ì¸ì¦ ë° í™•ì¥ êµ¬ì„±ì„ ë³´ì¥í•˜ì„¸ìš”.
â”‚   â”‚   â””â”€â”€ retrieval_service.py # Handles document retrieval
â”‚   â”œâ”€â”€ core                   # Core application components
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py          # Configuration settings
â”‚   â”‚   â””â”€â”€ logger.py          # Logging setup
â”‚   â””â”€â”€ utils                  # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ helpers.py         # Helper functions
â”œâ”€â”€ notebooks                  # Jupyter notebooks for setup and development
â”‚   â”œâ”€â”€ llm_setup.ipynb
â”‚   â””â”€â”€ rag_development.ipynb
â”œâ”€â”€ data                       # Directory for vector database files
â”‚   â””â”€â”€ vector_db
â”œâ”€â”€ requirements.txt           # Project dependencies
â”œâ”€â”€ Dockerfile                 # Docker image instructions
â”œâ”€â”€ docker-compose.yml         # Docker application configuration
â””â”€â”€ README.md                  # Project documentation
```

## Setup Instructions

1. **Clone the Repository**
   ```
   git clone <repository-url>
   cd llm-fastapi-server
   ```

2. **Install Dependencies**
   Use pip to install the required packages:
   ```
   pip install -r requirements.txt
   ```

3. **Run the FastAPI Server**
   You can start the FastAPI server using:
   ```
   uvicorn src.main:app --reload
   ```

4. **Access the API**
   Once the server is running, you can access the API at `http://127.0.0.1:8000`. The interactive API documentation can be found at `http://127.0.0.1:8000/docs`.

## Usage Examples

- **Generate a Response**
  Send a POST request to the `/generate` endpoint with your query to receive a response from the LLM.

- **Retrieve Documents**
  Use the `/retrieve` endpoint to fetch relevant documents from the vector database.

## Contributing

Contributions are welcome! Please submit a pull request or open an issue for any enhancements or bug fixes.

## License

This project is licensed under the MIT License. See the LICENSE file for more details.