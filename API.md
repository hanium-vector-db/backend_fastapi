# LLM FastAPI Server - API ëª…ì„¸ì„œ

## ğŸ“‹ ê°œìš”

ì´ ë¬¸ì„œëŠ” LLM FastAPI Serverì˜ ëª¨ë“  API ì—”ë“œí¬ì¸íŠ¸ì™€ ì‚¬ìš©ë²•ì„ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.

**ë² ì´ìŠ¤ URL:** `http://localhost:8001`

---

## ğŸ”¥ ì£¼ìš” ê¸°ëŠ¥

- **40ê°œ ì´ìƒì˜ ë‹¤ì–‘í•œ ë¡œì»¬ ì–¸ì–´ ëª¨ë¸ ì§€ì›**
- **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° í…ìŠ¤íŠ¸ ìƒì„±**
- **í•œêµ­ì–´, ì½”ë”©, ìˆ˜í•™ íŠ¹í™” ëª¨ë¸**
- **RAG (ê²€ìƒ‰ ì¦ê°• ìƒì„±) ê¸°ëŠ¥**
- **GPU ë©”ëª¨ë¦¬ ìµœì í™”**
- **ì‹¤ì‹œê°„ ëª¨ë¸ ì „í™˜**

---

## ğŸ¯ ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸

### 1. ì„œë²„ ì •ë³´ ì¡°íšŒ
```http
GET /
```

**ì‘ë‹µ ì˜ˆì‹œ:**
```json
{
  "message": "ğŸš€ LLM FastAPI ì„œë²„ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!",
  "version": "1.0.0",
  "description": "40ê°œ ì´ìƒì˜ ë‹¤ì–‘í•œ ë¡œì»¬ ì–¸ì–´ ëª¨ë¸ì„ ì§€ì›í•˜ëŠ” ê³ ì„±ëŠ¥ AI ì„œë²„",
  "features": [
    "ë‹¤ì–‘í•œ í¬ê¸°ì˜ LLM ëª¨ë¸ ì§€ì› (0.5B-72B)",
    "í•œêµ­ì–´, ì½”ë”©, ìˆ˜í•™ íŠ¹í™” ëª¨ë¸",
    "RAG (ê²€ìƒ‰ ì¦ê°• ìƒì„±) ê¸°ëŠ¥",
    "ì‹¤ì‹œê°„ ëª¨ë¸ ì „í™˜",
    "GPU ë©”ëª¨ë¦¬ ìµœì í™”"
  ],
  "endpoints": { ... },
  "supported_model_categories": [
    "ultra-light (0.5B)",
    "light (1-3B)", 
    "medium (7-13B)",
    "large (14B+)",
    "korean (í•œêµ­ì–´ íŠ¹í™”)",
    "code (ì½”ë”© íŠ¹í™”)",
    "math (ìˆ˜í•™/ê³¼í•™ íŠ¹í™”)",
    "multilingual (ë‹¤êµ­ì–´ ì§€ì›)"
  ]
}
```

### 2. ì„œë²„ ìƒíƒœ í™•ì¸
```http
GET /api/v1/health
```

**ì‘ë‹µ ì˜ˆì‹œ:**
```json
{
  "status": "healthy",
  "timestamp": "2024-01-01T00:00:00Z",
  "model_loaded": true,
  "current_model": "qwen2.5-7b"
}
```

---

## ğŸ¤– í…ìŠ¤íŠ¸ ìƒì„± API

### 1. ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒì„±
```http
POST /api/v1/generate
```

**ìš”ì²­ ë³¸ë¬¸:**
```json
{
  "prompt": "Pythonì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
  "max_length": 512,
  "temperature": 0.7,
  "top_p": 0.9,
  "stream": false
}
```

**ë§¤ê°œë³€ìˆ˜:**
- `prompt` (string, í•„ìˆ˜): ìƒì„±í•  í…ìŠ¤íŠ¸ì˜ í”„ë¡¬í”„íŠ¸
- `max_length` (integer, ê¸°ë³¸ê°’: 512): ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜
- `temperature` (float, ê¸°ë³¸ê°’: 0.7): ìƒì„±ì˜ ì°½ì˜ì„± ì¡°ì ˆ (0.0~2.0)
- `top_p` (float, ê¸°ë³¸ê°’: 0.9): í† í° ì„ íƒì˜ ë‹¤ì–‘ì„± ì¡°ì ˆ (0.0~1.0)
- `stream` (boolean, ê¸°ë³¸ê°’: false): ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ í™œì„±í™”

**ì¼ë°˜ ì‘ë‹µ:**
```json
{
  "response": "Pythonì€ 1991ë…„ ê·€ë„ ë°˜ ë¡œì„¬ì´ ê°œë°œí•œ ê³ ìˆ˜ì¤€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤...",
  "model": "qwen2.5-7b",
  "tokens_generated": 245
}
```

**ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (stream: true):**
```
data: {"content": "Pythonì€", "done": false}

data: {"content": " 1991ë…„", "done": false}

data: {"content": " ê·€ë„", "done": false}

...

data: {"content": "", "done": true}
```

### 2. ì±„íŒ… ìƒì„±
```http
POST /api/v1/chat
```

**ìš”ì²­ ë³¸ë¬¸:**
```json
{
  "message": "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë–¤ê°€ìš”?",
  "stream": false
}
```

**ì‘ë‹µ:**
```json
{
  "response": "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ë¼ì„œ ì‹¤ì‹œê°„ ë‚ ì”¨ ì •ë³´ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤...",
  "model": "qwen2.5-7b"
}
```

---

## ğŸ”— ì„ë² ë”© API

### ì„ë² ë”© ìƒì„±
```http
POST /api/v1/embed
```

**ìš”ì²­ ë³¸ë¬¸:**
```json
{
  "text": "ì„ë² ë”©í•  í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤"
}
```

**ì‘ë‹µ:**
```json
{
  "embedding": [0.1234, -0.5678, 0.9012, ...],
  "dimension": 1024,
  "model": "BAAI/bge-m3"
}
```

---

## ğŸ“š RAG (ê²€ìƒ‰ ì¦ê°• ìƒì„±) API

### RAG ì§ˆì˜
```http
POST /api/v1/rag
```

**ìš”ì²­ ë³¸ë¬¸:**
```json
{
  "query": "Pythonì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
  "k": 3,
  "stream": false
}
```

**ë§¤ê°œë³€ìˆ˜:**
- `query` (string, í•„ìˆ˜): ê²€ìƒ‰í•  ì§ˆì˜
- `k` (integer, ê¸°ë³¸ê°’: 3): ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜
- `stream` (boolean, ê¸°ë³¸ê°’: false): ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ

**ì‘ë‹µ:**
```json
{
  "answer": "Pythonì˜ ì£¼ìš” ì¥ì ë“¤ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤...",
  "sources": [
    {
      "content": "Pythonì€ ê°€ë…ì„±ì´ ë›°ì–´ë‚œ ì–¸ì–´ì…ë‹ˆë‹¤...",
      "score": 0.95
    }
  ],
  "model": "qwen2.5-7b"
}
```

---

## ğŸ›ï¸ ëª¨ë¸ ê´€ë¦¬ API

### 1. ì§€ì› ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
```http
GET /api/v1/models
```

**ì‘ë‹µ:**
```json
{
  "models": {
    "qwen2.5-7b": {
      "model_id": "Qwen/Qwen2.5-7B-Instruct",
      "description": "Qwen 2.5 7B - ê³ ì„±ëŠ¥ ë²”ìš© ëª¨ë¸",
      "category": "medium",
      "ram_requirement": "16GB",
      "gpu_requirement": "8GB",
      "performance_score": 85,
      "use_cases": ["general", "korean", "coding"]
    },
    "llama3.1-8b": {
      "model_id": "meta-llama/Meta-Llama-3-8B-Instruct",
      "description": "Meta Llama 3 8B - ê³ ì„±ëŠ¥ ëª¨ë¸",
      "category": "medium",
      "ram_requirement": "16GB",
      "gpu_requirement": "8GB",
      "performance_score": 88,
      "use_cases": ["general", "coding", "reasoning"]
    },
    "gemma-3-4b": {
      "model_id": "google/gemma-2-9b-it",
      "description": "Google Gemma 2 9B - íš¨ìœ¨ì ì¸ ì¤‘í˜• ëª¨ë¸",
      "category": "medium",
      "ram_requirement": "18GB",
      "gpu_requirement": "10GB",
      "performance_score": 82,
      "use_cases": ["general", "multilingual"]
    }
  }
}
```

### 2. ëª¨ë¸ ì¹´í…Œê³ ë¦¬ ì¡°íšŒ
```http
GET /api/v1/models/categories
```

**ì‘ë‹µ:**
```json
{
  "categories": ["medium"]
}
```

### 3. ì¹´í…Œê³ ë¦¬ë³„ ëª¨ë¸ ì¡°íšŒ
```http
GET /api/v1/models/category/{category}
```

**ì˜ˆì‹œ:** `/api/v1/models/category/medium`

### 4. ëª¨ë¸ ì¶”ì²œ
```http
POST /api/v1/models/recommend
```

**ìš”ì²­ ë³¸ë¬¸:**
```json
{
  "ram_gb": 16,
  "gpu_gb": 8,
  "use_case": "korean"
}
```

**ì‘ë‹µ:**
```json
{
  "recommendations": [
    {
      "model_key": "qwen2.5-7b",
      "model_info": { ... },
      "recommendation_score": 85,
      "reasons": [
        "RAM ìš”êµ¬ì‚¬í•­ ì¶©ì¡± (16GB)",
        "GPU ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­ ì¶©ì¡± (8GB)",
        "'korean' ìš©ë„ì— ì í•©"
      ]
    }
  ]
}
```

### 5. ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
```http
POST /api/v1/models/compare
```

**ìš”ì²­ ë³¸ë¬¸:**
```json
{
  "model_keys": ["qwen2.5-7b", "llama3.1-8b"]
}
```

### 6. ëª¨ë¸ ê²€ìƒ‰
```http
GET /api/v1/models/search?q=korean
```

### 7. ëª¨ë¸ í†µê³„
```http
GET /api/v1/models/stats
```

### 8. ëª¨ë¸ ì „í™˜
```http
POST /api/v1/models/switch
```

**ìš”ì²­ ë³¸ë¬¸:**
```json
{
  "model_key": "llama3.1-8b"
}
```

### 9. íŠ¹ì • ëª¨ë¸ ì •ë³´
```http
GET /api/v1/models/info/{model_key}
```

---

## ğŸ’» ì‹œìŠ¤í…œ ì •ë³´ API

### GPU ì •ë³´ ì¡°íšŒ
```http
GET /api/v1/system/gpu
```

**ì‘ë‹µ:**
```json
{
  "gpu_available": true,
  "gpu_count": 1,
  "gpu_memory": "8GB",
  "cuda_version": "11.8"
}
```

---

## ğŸ¨ UI ì¸í„°í˜ì´ìŠ¤

### 1. Gradio UI
```
GET /ui
```
- ëŒ€í™”í˜• ì›¹ ì¸í„°í˜ì´ìŠ¤
- ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì§€ì›
- ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ìƒì„±

### 2. ì»¤ìŠ¤í…€ ìŠ¤íŠ¸ë¦¬ë° UI
```
GET /stream
```
- ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì „ìš© ì¸í„°í˜ì´ìŠ¤
- Server-Sent Events ê¸°ë°˜
- ë¹ ë¥¸ ì‘ë‹µ ì†ë„

---

## ğŸ“– ë¬¸ì„œ

### 1. API ë¬¸ì„œ (Swagger UI)
```
GET /docs
```

### 2. API ë¬¸ì„œ (ReDoc)
```
GET /redoc
```

---

## ğŸš¨ ì˜¤ë¥˜ ì½”ë“œ

| ìƒíƒœ ì½”ë“œ | ì„¤ëª… |
|---------|-----|
| 200 | ì„±ê³µ |
| 400 | ì˜ëª»ëœ ìš”ì²­ |
| 404 | ë¦¬ì†ŒìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ |
| 500 | ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ |

**ì˜¤ë¥˜ ì‘ë‹µ ì˜ˆì‹œ:**
```json
{
  "error": "ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
  "detail": "ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë¸: unknown-model"
}
```

---

## ğŸ“ ì‚¬ìš© ì˜ˆì‹œ

### Pythonìœ¼ë¡œ API í˜¸ì¶œ
```python
import requests
import json

# ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒì„±
response = requests.post("http://localhost:8001/api/v1/generate", 
    json={
        "prompt": "Pythonì˜ ì¥ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
        "max_length": 256,
        "stream": False
    }
)
print(response.json()["response"])

# ìŠ¤íŠ¸ë¦¬ë° ìƒì„±
response = requests.post("http://localhost:8001/api/v1/generate",
    json={
        "prompt": "AIì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
        "stream": True
    },
    stream=True
)

for line in response.iter_lines():
    if line:
        data = json.loads(line.decode().replace('data: ', ''))
        if not data.get('done'):
            print(data['content'], end='', flush=True)
```

### JavaScriptìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ
```javascript
const response = await fetch('/api/v1/generate', {
    method: 'POST',
    headers: {
        'Content-Type': 'application/json',
    },
    body: JSON.stringify({
        prompt: 'JavaScriptì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”',
        stream: true
    })
});

const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    const chunk = decoder.decode(value);
    const lines = chunk.split('\n');
    
    for (const line of lines) {
        if (line.startsWith('data: ')) {
            const data = JSON.parse(line.slice(6));
            if (!data.done) {
                console.log(data.content);
            }
        }
    }
}
```

---

## ğŸ”§ ì„¤ì •

### í™˜ê²½ ë³€ìˆ˜
- `HUGGINGFACE_TOKEN`: Hugging Face í† í° (í•„ìˆ˜)
- `SERVER_HOST`: ì„œë²„ í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: 0.0.0.0)
- `SERVER_PORT`: ì„œë²„ í¬íŠ¸ (ê¸°ë³¸ê°’: 8001)

### ëª¨ë¸ ìºì‹œ
- ê¸°ë³¸ ìºì‹œ ë””ë ‰í† ë¦¬: `C:\huggingface_models`
- ì²« ì‹¤í–‰ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¡œ ì‹œê°„ ì†Œìš”

---

## ğŸ“ ì§€ì›

ë²„ê·¸ ë¦¬í¬íŠ¸ë‚˜ ê¸°ëŠ¥ ìš”ì²­ì€ GitHub Issuesë¥¼ í†µí•´ ì œì¶œí•´ì£¼ì„¸ìš”.
  
**ìµœì¢… ì—…ë°ì´íŠ¸:** 2025-08-25